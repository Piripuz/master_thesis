\chapter{Methodology}
\label{chap:methodology}

This chapter presents the methodology used throughout the thesis.
It will be articulated in different parts, according to how the thesis will proceed:
the first step will involve building the model
and finding a suitable method for retrieving the parameters from data.
After this, the method must be tested on several different scenarios of increasing complexity.
These include an initial synthetic dataset built accordingly to the model,
data simulated with a generic traffic simulator and, eventually,
real data from the sources described above.

The first step is thus giving an overview of the methods that are suitable for inferring the parameters from the data,
and explaining what was the chosen method and the reasons that determined its choice.

\section{Inference Methods}
\label{sec:inference}

For retrieving parameters from the data, different methods could be used,
each one of which is better suited for a different problem.
In order to choose one of these methods, a more formal statement of the problem is necessary.

In the following lines, the inference problem is more formally stated,
in order to acquire a deeper understanding of it and to be able to choose the right inference method.
After that, the available methods will be presented and the most suitable one will be chosen from them.

\subsection{Theoretical Preliminaries}
\label{sec:theo_pre}

As stated in the introduction, we are assuming that each user is minimizing a cost function,
that has the form in \eqref{eq:cost_intro}:
\begin{equation}
  \label{eq:cost_init_inf}
  C(t) = \alpha(\text{travel time}) + \beta (\text{time early}) + \gamma (\text{time late})
\end{equation}
Let then \(t^*\) be the desired arrival time,
\(tt(t)\) the travel time if leaving from the origin at time \(t\) and
\([\bullet]^+\) the function that is known in machine learning as \textit{ReLU}, that is,
\([x]^+ = \max(0, x)\).

The \textit{time early} becomes thus the difference between the desired arrival time \(t^*\) and the actual arrival time \(t + tt(t)\), cut at zero:
\[\text{time early} = [t^* - tt(t) - t]^+\]
Similarly, for \textit{time late}
\[\text{time late} = [tt(t) + t - t^*]^+\]
The expression for the cost in \eqref{eq:cost_init_inf} becomes thus

\begin{equation}
  \label{eq:cost_inf}
  C(t; \alpha, \beta, \gamma, t^*) = \alpha tt(t) + \beta [t^* - tt(t) - t]^+ + \gamma[tt(t) + t - t^*]^+
\end{equation}

Each user is thus minimizing (over the variable \(t\))
a function that is parametric, with four different parameters:
the user preferences \(\alpha, \beta, \gamma\) and the desired arrival time \(t^*\).
This minimization will yield an optimal departure time \(t^{opt}\),
that will vary in function of the parameters:
\begin{equation}
  \label{eq:t_opt}
  t^{opt} = t^{opt}(\alpha, \beta, \gamma, t^*) = \min_{t \in (0, 24)} C(t; \alpha, \beta, \gamma, t^*)
\end{equation}

Suppose now that all four parameters are distributed across the different commuters,
and the parameter of each commuter are sampled from four different random variables,
whose probability distribution functions are parametrized by a parameter \(\theta \in \R^n, n \geq 1\).
The minimization process yields another random variable, parametrized by the same parameter \(\theta\),
which describes the optimal departure time \(t^{opt}\).
Let \(T^{opt}\) be this random variable, and
\begin{equation}
  \label{eq:pdf_opt}
  f_{T^{opt}}(t; \theta)
\end{equation}
its Probability Density Function.

The inference problem is thus the following:
a dataset is given,
which is close to what would result from sampling from the random variable \(T^{opt}\).
What is the value of the parameter \(\theta\) that the best explains the dataset?

For answering this question, the parameter has to be inferred from the data,
and an approach for doing this has to be chosen.
It is well known how the inference methods are divided in Bayesian and Frequentist inference
(for a really in-depth review of the discussion, see \cite{bandyopadhyay2011philosophy}).
The main inference methods are thus either Bayesian methods (for an overview, see \cite{gelman2013bayesian}) or simpler Maximum Likelihood \parencite{doi:10.1098/rsta.1922.0009}.
The following sections better describe the different approaches,
and discuss how are they applicable to the examined problem.

\subsection{Maximum Likelihood Estimation}
\label{sec:max_lik}
The Maximum Likelihood Estimation is the simplest, oldest and probably most widely used method examined here.

The methods relies on a simple idea:
for each value of the parameter \(\theta\),
each data point will have a certain \textit{likelihood} (or, in the discrete case, probability) of being a realization of the random variable \(T^{opt}\).
It is thus a good idea to look for the value of \(\theta\) that maximises the likelihood for the whole given dataset:
this value will thus be called the Maximum Likelihood Estimator (MLE) estimate.

More formally, let \(f_{T^{opt}}(t; \theta)\) be (as in \eqref{eq:pdf_opt}) the probability density function for the random variable \(T^{opt}\).

The \textit{likelihood} of the parameter \(\theta\) given the observation of a data point \(s\) is defined as
\begin{equation}
  \label{eq:lik_one_point}
  \lik(\theta | s)  = f_{T^{opt}}(s; \theta)
\end{equation}

More generally, let
\[S = \{t_1, \dots, t_N\}\]
be the given dataset of the actual departure times,
that can be thought of as independent samples of the random variable \(T^{opt}\).

Since the joint probability of independent events can be computed by multiplying the probabilities of the individual events,
the likelihood of the parameter \(\theta\) (given the dataset \(S\)) will be defined as
\begin{equation}
  \label{eq:lik_def}
  \lik(\theta | S) = \prod_{s \in S} f_{T^{opt}}(s; \theta)
\end{equation}

The MLE estimate \(\hat{\theta}\) is now simply defined as the value of the parameter \(\theta\) that maximises the likelihood:
\begin{equation}
  \label{eq:mle_estimate}
  \hat{\theta} = \argmax_\theta \lik(\theta | S)
\end{equation}

The maximization of the likelihood function can be performed in different ways:
when possible, an analytical maximization could be the fastest and most precise estimation method.
Finding an analytical solution is anyway not always viable,
since the function can have a convoluted analytical expression.
Widely used methods include thus numerical optimization methods,
often via gradient descent
(in the cases where the likelihood is differentiable, and the gradient is easy to compute)
or even via gradient-free optimizers using, for instance,
the simplex method \parencite{10.1093/comjnl/7.4.308}.
The optimization methods will be investigated further in Section \ref{sec:max_lik_meth}

Even being this the simplest method, it presents some challenges:
the likelihood is indeed not trivial to estimate,
as the random variable \(T^{opt}\) is defined itself as the minimization of a cost function.
Moreover, the computation of the likelihood has to be done fast enough to allow an optimizer to run on it,
in case the computed likelihood does not allow an analytical maximization (that is highly likely,
given how the likelihood is defined).

These problems, which will equally affect the other estimation methods,
will be tackled in Section \ref{sec:lik_est}.
I will thus here present the other main estimation method.

\subsection{Bayesian Estimation}
\label{sec:bayes}

The bayesian approach is a philosophically (beyond practical) different way of looking at the problem.
According to this approach, parameters are not indeed seen as real variables that can be maximised,
but rather as random variables themselves,
some prior knowledge of which can be integrated in the model.

Consider, for instance, an inference problem in which
the height \(h\) of a group of people has to be estimated.
A likelihood that is maximised for an unrealistic value of the parameter (e. g., \(h = 15 \unit{\cm}\)) is extremely unhelpful when doing an MLE,
and would lead to a wrong estimation.
Using bayesian methods, on the other hand,
it is possible to consider some prior knowledge about the parameter before doing the estimation
(for instance, the parameter can be believed to be distributed close to the average height of a person).
Data will thus enhance this knowledge,
specified by the choice of a \textit{prior} distribution,
and transform it to another distribution, called \textit{posterior} distribution.

Sadly, in our case, having a meaningful prior distribution is quite difficult:
as noted in Section \ref{cha:introduction},
knowledge about the distribution of them is limited.
A decision was thus taken to estimate the parameters by simply maximising the likelihood,
not taking in consideration any information on the prior.

It is thus important to study the likelihood,
in order to be able to perform the parameter estimation at the core of the project.

\section{Estimation of the Likelihood}
\label{sec:lik_est}
To estimate the likelihood, two main approaches are viable:
one could either analytically find the expression for the likelihood,
that requires doing a more extensive and heavier theoretical work,
but yields a more precise and (potentially) better performing method,
or choose to sample data points (by directly minimizing the cost function)
to perform a subsequent maximization on what is known as \textit{empirical likelihood} \parencite{10.1093/biomet/75.2.237}:
a nonparametric estimation of the likelihood function from a set of samples.

While the standard approach could provide a way of quickly computing the likelihood
(enhancing as well the knowledge of the subject),
empirically approximating it could yield an acceptable approximation and would not require as much theoretical understanding as the direct computation.
But, since theoretical understanding of the problem is not something to be neglected,
both methods deserve to be presented.

\subsection{Empirical Approximation of the Likelihood}
\label{sec:emp_approx_lik}

Empirical estimation of the likelihood is a method that was first defined by \textcite{10.1093/biomet/75.2.237}.
It consists in the estimation of the likelihood based on the \textit{empirical Cumulative Distribution Function} (eCDF)  \(\hat{F}(x)\) (simply, the ratio between the number of samples before the point in which the function is evaluated and the number of the total samples),
and only requires an arbitrary number of independent and identically distributed (i.i.d.) samples.
The next paragraph will briefly explain how does the method work.

Consider a set \(S = \{t_1, \dots, t_N\}\) of \(N\) i.i.d. samples from the distribution we want to calculate the likelihood of.
The eCDF for the set of samples \(S\) will be defined as
\begin{equation}
  \label{eq:emp_cdf}
  \hat{F}(t) = \frac{1}{N}\sum_{i = 1}^N \mathbb{1}_{t_i \leq t}
\end{equation}
where \(\mathbb{1}_A\) is the \textit{indicator} of event \(A\),
evaluating to 1 if \(A\) occurs, and to 0 otherwise.

The empirical likelihood of a data point x can now simply be defined as

\begin{equation}
  \label{eq:emp_lik}
  L(x) = \frac{\hat{F}(x) - \hat{F}(x - \delta)}{\delta}
\end{equation}
where \(\delta\) is a parameter,
to be set as small as the size of the set \(S\) allows
(note indeed that, if no samples appear between \(x\) and \(x - \delta\), the likelihood \(L(x)\) will be equal to zero).
For a more in-depth discussion of the empirical likelihood and its properties, see \textcite{annurev:/content/journals/10.1146/annurev-statistics-040720-024710}.

This method is certainly relevant for the problem examined in this thesis:
the likelihood could indeed be computed regardless of the distributions of the parameters \(\alpha, \beta, \gamma, t^*\),
as long as sampling from their distributions is easy enough.
Once a sample has been taken from each of their distributions,
minimizing the cost function yields a data point in the set \(S\).
By drawing independent samples from the chosen distributions for the parameters,
the set \(S\) can be built to a sufficient size.
The likelihood of the given dataset can then be estimated against the sampled data,
and subsequently maximized.

The biggest drawback of this effort concerns the computational complexity:
for each estimation of the likelihood function,
a sufficient number of samples has to be drawn from the hypothesized parameter distributions,
and a minimization has to be performed over the cost function after each set of parameters is drawn.
Moreover, this method would not allow the computation of the gradient of the likelihood;
the minimization would thus have to be computed using gradient-free optimizers,
which typically involves a big number of function evaluations \parencite{Larson_Menickelly_Wild_2019} which would be,
in this case, particularly complex.

This problem could be avoided by using modern high performance computing frameworks,
and powerful machines.
It is anyway a major drawback and suggests, if possible, the adoption of alternative methods.

\subsection{Direct Computation of the Likelihood}
\label{sec:lik_comp}

As mentioned earlier, the obvious method of computing a likelihood is the direct computation of it.

Even looking obvious, this approach is not completely trivial to develop:
note indeed that the random variable \(T^{opt}\) is defined by minimizing the cost function,
in which several other random variables appear.

For obtaining an analytical expression for the Probability Density Function \(f_{T^{opt}}(t; \theta)\), different steps are thus required:
first of all, a complete understanding of how changing the different parameters affects the cost function has to be developed.
Subsequently, where the cost is minimized has to be studied;
the dependency of the point that minimizes the cost on each one of the parameters has to be characterized.
Lastly, the characterization has to be extended to the case in which the parameters are distributed rather than real values.

This process could be particularly laborious,
but once done it could provide an elegant and precise estimation method:
having a full characterization of the points that minimize the cost function \(C(t; \alpha, \beta, \gamma, t^*)\) would indeed require a deep knowledge of the problem,
and this is, herein, interesting by itself in addition to being useful.

Despite being challenging,
this approach is the chosen one:
it will yield a complete characterization of the distribution of the random variable \(T^{opt}\).

Once the analytical expression for the likelihood is found,
the estimation is not done at all:
computing the likelihood will indeed require computations that can only be numerically approximated,
and whose approximation with a good precision requires a big computational effort.
The following section delves a bit deeper in the problem,
and presents some solutions that can help in mitigating the issues.

\subsection{Speeding Up the Likelihood Computation}
\label{sec:lik_speed}
As stated in the previous paragraph, numerically computing the Probability Density Function of the variable \(T^{opt}\) will,
by itself, not be a trivial task.
Moreover, the computation has to be repeated a big number of times for performing the final MLE estimate for the parameter \(\theta\):
the value of the pdf has indeed to be computed for each point in the dataset,
and once this computation has been done the final result has to be maximised,
requiring the whole computation to be performed as many times as the maximization algorithm requires to.
Moreover, being able to perform a gradient descent on the result of the likelihood would greatly reduce the number of times the computation is performed,
while the simpler algorithms would be considerably slower by requiring a larger number of function evaluations.

The problems in the evaluation of the likelihood are mainly two:
the first one is the need of evaluating integrals of function whose primitive is not analytically computable;
the second one is the need of inverting some functions whose inverse does not have a closed form analytical expression.

Both problems are solvable,
since there exist methods that find the solutions with arbitrary precision,
as long as the functions are behaved well enough (that is the case in this problem).

Regarding the integration, the solution can be approximated by using the trapezoid method,
that requires a finite number of function evaluations and yields a good estimate of the integral
(for a deeper discussion on this, see \cite{Sueli_Mayers_2003}).
An approximated integral via the trapezoid method can thus be computed and,
if gradient descent has to be performed on its result,
the derivative of it can be computed.
The differentiation is anyway not feasible analytically, since it involves a great number of terms.
In order to properly differentiate it,
an automatic differentiation framework is needed.

For what concerns inverting functions, the problem is again computationally tractable,
as the inverse can be approximated iteratively by using a biSection method or,
in some particular cases, a gradient descent algorithm.
Anyway, differentiating the result of an iterative method does not even have a general meaning,
and is thus not doable.
A method recently developed at Google,
called implicit differentiation \parencite{DBLP:journals/corr/abs-2105-15183},
allows anyway to numerically approximate the gradient of the result of optimization techniques.
The method is efficiently implemented for the automatic differentiation framework JAX \parencite{jax2018github}
that, on top of allowing the computation of gradients,
speeds up by several orders of magnitude the written code (compared to standard Python implementations)
by leveraging just-in-time compilation and hardware acceleration.
Utilizing this library will be fundamental in the development of the thesis,
by allowing the computations to be executed in tolerable times even on normal, consumer-grade machines.

After the likelihood has been efficiently computed,
inferring the parameters requires it to be maximised.
An overview of the possible maximisation methods is thus given in the following Section.

\section{Maximization of the Likelihood}
\label{sec:max_lik_meth}

The ideal way of finding the maximum of the likelihood would be differentiating it,
inverting the derivative and analytically computing the result.
This is sadly not possible in general,
since the expression for the likelihood could be very convoluted and,
as a consequence,
the derivative can become analytically intractable.

To solve this problem,
the maximum will be numerically approximated.
Different techniques can be used for the approximation of it,
and they will be presented in this Section.

\subsection{Grid Search}
\label{sec:grid_search}

The most basic and intuitive solution for maximising a function (after randomly selecting a point to be the maximum) is grid search:
the function is evaluated on a set of equally spaced points spread over its domain,
and the point in which the function assumes the highest value is chosen as the approximated maximum.

Despite being a naive solution,
this method offers some advantages compared to other more sophisticated algorithms.
A grid search is indeed unlikely to output a local minimum,
since no information about whether the function is growing is ever used.
Moreover, the algorithm is not inherently iterative,
and as such greatly parallelizable.

On the other hand,
this solution has an undeniable drawback:
the precision of the convergence is really low,
and improving it requires an enormous computational effort.
Some techniques have been proposed to overcome this limitation
(as in \cite{pathak2024randomizedgridsearchhyperparametertuning,postuvan2022adagridadaptivegridsearch}),
but often combining it with an iterative maximization algorithm offers the best results.

Iterative methods are thus examined in the next sections.

\subsection{Gradient Descent Methods}
\label{sec:grad_desc}

Gradient descent (and the various modified versions of it) is arguably the most widely known and used method in optimization \parencite{ruder2017overviewgradientdescentoptimization}.
It is based on a simple idea:
it is easy to prove that, for a differentiable function,
the direction in which the value of the function increases the fastest (clearly, locally)
is the one pointed by the gradient.
Once the gradient has been computed, evaluating it at a point gives thus a suggestion (as long as the function is behaved well enough) on the direction in which the maximum can be computed.

More formally, let
\begin{align*}
  J: \R^d & \rightarrow \R \\
  \theta & \mapsto J(\theta)
\end{align*}
the function that has to be minimised
(if the function has to be maximised, it is sufficient to change the sign of it).

Let \(\nabla J(\theta)\) be the gradient of it with respect to the variable \(\theta\),
and \(\theta_0 \in \R^d\) some initial value from where the optimization has to be started.
According to the gradient descent algorithm,
the current estimation is updated as follows:
\begin{equation}
  \label{eq:grad_desc}
  \theta_{i+1} = \theta_i - \alpha_i\nabla J(\theta_i)
\end{equation}
where \(\alpha_i\), called \textit{step size}, depends on the chosen optimization strategy.

The step size can be either constant, yielding a more predictable but often slower or less precise convergence,
or variable.
In the case in which the step size is not constant,
it can be changed in a variety of different ways,
defining several different gradient descent algorithms with their strengths and weaknesses
\parencite{doi:10.1137/1011036,MR701288}.

For a deeper discussion on these methods, including how the step size can be chosen,
see \cite{10.5555/3317111}.

Many of the strengths and weaknesses of these methods are anyway common across all of them,
and the major weakness is, in many cases,
the need of computing the gradient.

In our case, the gradient of the likelihood can be computed via, as presented in Section \ref{sec:lik_speed},
modern computational frameworks which allow implicit differentiation.
The methods may anyway have issues with numerical stability,
and need careful tuning for avoiding regions that are out of the domain\footnote{As reported in a conversation with a JAX developer}.
This problem could, in principle,
make the computation of the gradient not feasible.
In this case, iterative algorithms such as gradient-less optimizers could still yield good results.

\subsection{Simplex Method}
\label{sec:no_grad_opt}

It may happen, in general, that no information is available other than the function values,
making it impossible to compute the gradient,
or particularly expensive to estimate it.

For addressing this type of problems, some optimization techniques that only rely on the values of the function at some points,
without needing anything else,
have been developed.
I will focus here on the method that is arguably the most popular among them,
developed by \textcite{10.1093/comjnl/7.4.308}.
For a deeper review of the different methods, see \cite{10.5555/1508119}.

The simplex method, as its name suggests, is based on the estimation of the function on the edges of a simplex.
The simplex is simply the extension of a triangle to an arbitrary-dimensional euclidean space:
in dimension \(d\), the method will thus maintain \(d+1\) points,
and update their position at each iterate.

The update can be done in four different ways:
depending on some conditions on the value of the function at the edges,
\textit{reflection} reflect one of the points with respect to the centroid of the remaining ones;
\textit{expansion} on top of reflecting a point, moves it away from the centroid of the other edges, by a linear factor;
\textit{contraction} is similar to the expansion, but instead of moving the edge away from the centroid it moves it closer;
finally, if none of the conditions for the other updates is satisfied,
\textit{shrinking} is performed:
each point is pulled towards the best one proportionally on their distance from it.
When the simplex is lying on a \textit{flat} surface (that is, when the values of the function at its edges are close enough),
the method is terminated and the edge in which the function assumes the lowest value is returned as the minimum.

This method achieves convergence with a relatively small number of function evaluations,
since the values of the function at the edges can be stored in memory.
Despite this, it presents two major drawbacks.
The first one is about the number of function evaluations:
while the method does not require a big number of them if compared with gradient-free methods,
the number of function evaluations it requires can exceed the ones required by gradient methods by different orders of magnitude.
The second drawback regards the optimum found by the method:
as found by \textcite{doi:10.1137/S1052623496303482},
the method can indeed converge to nonstationary points,
where the gradient is not null and a gradient based optimizer would escape.
This phenomenon can be reduced by tweaking the parameters,
but occurs in different situations and can be an obstacle to the proper convergence of the estimate.

This method will thus be used only when unavoidable,
and avoided in favour of gradient-based methods when possible.

Once the likelihood has been maximised,
the method has to be tested on scenarios in which the convergence can be evaluated,
in order to prove it to actually be meaningful.
The following Sections will present how the evaluation will be performed,
on various scenarios of increasing complexity.

\section{Evaluation on Synthetic Data}
\label{sec:eval_synth}

The first, simplest scenario for testing the method consists in building a dataset of artificial observations of departure times,
from a purely theoretical (and well behaved) travel time function.
Building the dataset without any connection with real scenarios will not yield important data regarding the usefulness of the method when real data will be used.
However, it provides a nice instrument for evaluating the convergence properties of the method.
Moreover, evaluating the method on a tailored dataset efficiently separates the method from the underlying theory:
this step will enable to evaluate the method without it being affected by potential faults of the bottleneck modelling we assume.

To perform this evaluation, the first thing that needs to be done is ing the dataset.

\subsection{Building the Synthetic Dataset}
\label{sec:synth_dataset}

The dataset has to be built independently from the theory developed when estimating the likelihood,
since a theory cannot be used for evaluating itself.

The most independent way to build a synthetic dataset is thus to computationally minimise the cost function for each agent,
and to find in this way the chosen departure time.

Remind that, from \eqref{eq:cost_inf}, the cost is equal to
\begin{equation*}
  C(t; \alpha, \beta, \gamma, t^*) = \alpha tt(t) + \beta[t^* - tt(t) - t]^+ + \gamma[tt(t) + t - t^*]^+
\end{equation*}

To minimize it, a specification of the travel time function \(tt(t)\) is thus needed,
in addition to the parameters \(\alpha, \beta, \gamma, t^*\).
The travel time function can be chosen to have an arbitrary analytical form,
as long as it satisfies the theoretical properties one expects from it (that will be defined further ahead).
On the other hand, the parameters will be sampled from the chosen distribution,
parametrized by the parameter \(\theta\).

Once the cost function has been defined,
the minimization has to occur.
Since the cost can have up to three local minima (as shown in Section~\ref{sec:local_min}),
three different optimizers are run on it,
each one of which aimed at one of the minima.
The retrieved values are then compared, and the global minimum is found in this way.
This procedure can be run for an arbitrary number of time,
in order to obtain dataset of the desired size \(N\).

With this method, both the size of the dataset \(N\) and the parameter \(\theta\) can be tweaked as much as needed:
convergence can in this way be evaluated for many shapes of the distribution,
to ensure the robustness of the developed method.

Once the dataset has been built,
the model will be tested with the artificial data.

\subsection{Running the Model on Synthetic Data}
\label{sec:run_synth_dataset}

Being run is exactly the purpose of the model and is not thus particularly complex.
Some comments on how the model is evaluated can anyway be made to comprehend it better.

As explained in Section \ref{sec:thesis_obj},
the model's input must be the dataset about when people actually leave from the origin of their trip and the travel time function.
In this case, both of these input are readily available and easy to get:
the travel time function has some analytical form that has been decided earlier,
while the dataset of departure times has just been built.

Running the model will thus produce an estimate \(\hat{\theta}\) of the original distribution parameter \(\theta\).
Being the parameter in a low-dimensional space,
convergence can be assessed by visual inspection of the results.

If an objective measure of it is needed, it can then be evaluated by simply computing the Mean Square Error
\begin{equation*}
  MSE = \sqrt{\sum_i (\theta_i - \hat{\theta}_i)^2}
\end{equation*}
and studying how it changes when \(\theta\), \(N\) are changed.

Moreover, the likelihood of different values of the parameter \(\theta\) can be computed.
This allows, by evaluating a grid of different parameters,
to do some plots of slices of the likelihood (necessary if the parameter satisfies \(\theta \in \R^d, d > 2\)),
and having thus an overview on how well-behaved the likelihood is.

Concluding, evaluating the method on a synthetic dataset is far from the final goal of the model.
Anyway, it provides some important ways of evaluating the developed model,
before dealing with more realistic but more difficultly interpretable scenarios.

The next step is to evaluate the model on a scenario that is more realistic than a simple synthetic dataset,
but for which the convergence can still be evaluated.
Traffic simulators, and in particular METROPOLIS2 (in which the parameters \(\alpha, \beta, \gamma\) can be explicitly set for each agent),
are extremely helpful in this stage.

\section{Evaluation on Data from Traffic Simulator}
\label{sec:eval_metr}

A traffic simulator can provide precious insights on the value of the model:
it indeed consists of a deeply customizable setting,
suitable for providing data about the most simple scenarios (such as a single bottleneck)
while converging to the reality as the scenario gets more and more complex.
Moreover, as noted above,
they can be used as a measure of the convergence without building real surveys on purpose,
which can be very expensive and complex ways to test the convergence of a model.

Many different traffic simulation programs have been written over the years
(for a review of the existing ones, with their respective strengths and weaknesses, see \cite{NGUYEN2021100486}).
To the best of our knowledge though,
the one that the most respects the specifications of Vickrey's model \parencite{LI2020311} is METROPOLIS,
a traffic simulator written by \textcite{de1997metropolis} and its succesor METROPOLIS2, by \textcite{RePEc:ema:worpap:2024-03}.
I will mainly focus, in this thesis,
on the faster and more recent METROPOLIS2,
which provides a more precise convergence and more flexible simulation,
at the cost of (currently) some of the ease of use.
The next Section will thus briefly cover the working principle of the simulator,
to later delve into how it can be used for the thesis' purpose.

\subsection{METROPOLIS2 Working Principle}
\label{sec:metr}

Traffic simulators can usually be distinguished into microscopic simulators,
which model traffic at small scales such as the single neighbourhood \parencite{8569938},
and macroscopic simulators, which model it to large scales,
such as cities or whole countries \parencite{mcnally2007four}.

METROPOLIS does not fit in any of these categories:
it is indeed defined a \textit{mesoscopic} traffic simulator \parencite{RePEc:ema:worpap:2024-03},
which adopts an intermediate approach between micro- and macroscopic simulators.
It is indeed built following an agent-based methodology,
in which each user behaves independently,
according to the travel time function defined by the collectivity.

The simulator works in an iterative way,
and at each iteration the agents improve their behaviour,
based on last iteration's results.
Once a number of iterations (or \textit{days}) has been decided,
the simulation works by running three different models for each day, as shown in figure~\ref{fig:metr_func}:
the \textit{demand} model, the \textit{supply} model and the \textit{learning} model.

In the demand model, the agents decide,
based on the last iteration's final network conditions,
what decisions to make about their travel:
when to leave, and what route to choose (or travel alternative, in case they can choose from more than one of these);
in the supply model, the conditions of the network are computed:
the decisions of all the users are taken into account, and the experienced travel time for that day
(for each link in the network) is computed;
finally, the learning model computes the \textit{expected} network conditions:
according to a predefined learning function,
the network conditions of all the previous days are averaged and what the users expect for the next day is decided.
Equilibrium is reached when the decisions of the users do not relevantly change after each day,
or equally when the expected network conditions reach a stationary situation.
\begin{figure}
  \centering
  \begin{tikzpicture}
    [block/.style={draw,minimum width=#1,minimum height=3em},
    block/.default=10em,high/.style={minimum height=3em},auto,
    node distance=5mm, % initially 1cm
    >=Stealth]
    
    \node[align=center] (n0) {Input\\Parameters};
    \node[block=3em,right=1cm of n0] (n1) {Demand Model};
    \node[block=3em, right=2cm of n1] (n2) {Supply Model};
    \node[block=3em, right=2cm of n2] (n3) {Learning Model};

    \draw[->] (n0) -- (n1) coordinate[midway] (in);
    \draw[->] (n1) edge node[midway,align=center] {Travel\\choices} (n2);
    \draw[->] (n2) edge node[midway,align=center] {Actual\\Network\\Conditions} (n3);
    
    \coordinate (x) at ([yshift=-1cm]n3.south);
    \coordinate (y) at (in |- x);
    
    \draw (n3.south) -- (x) edge node[above,midway,align=center] {Forecasted Network Conditions} (y) (y) edge[->] (in);
  \end{tikzpicture}
  \caption{Working principle of the traffic simulator METROPOLIS2:
    for each day (or iteration), three different models are ran.
    The demand model, given the forecasted network conditions, outputs the travel choices of the agents;
    the supply model takes them in input and outputs the network conditions.
    Finally, the Learning model combines the network condition with the historical observed network conditions (from past days) for outputting a forecast on next day's conditions.
  The image was inspired by \textcite{RePEc:ema:worpap:2024-03}.}
  \label{fig:metr_func}
\end{figure}

When choosing the best departure time for each trip,
the users decide accordingly to some probabilities, arising from a continuous logit model:
if for a user departing at time \(t\) costs \(C_i(t)\),
their time of departure will be modeled as a random variable whose Probability Density Function is
\begin{equation}
  \label{eq:cost_logit}
  f_i(t) = \frac{e^{\frac{C_i(t)}{\mu}}}{\int_0^{24}e^{\frac{C_i(s)}{\mu}}ds}
\end{equation}
where the parameter \(\mu\) is a noise parameter:
for \(\mu \rightarrow 0\), the random variable goes towards a dirac distributed one around the minimizer of the cost \(t^{opt}\),
while for high values of \(\mu\) it tends towards an uniformly distributed random variable.

For the convergence to equilibrium, the model relies heavily\footnote{As noted in private discussions with Lucas Javaudin and AndrÃ© de Palma} on the value of the noise parameter \(\mu\),
and will not converge for low values of it.
This will potentially create some problems when validating with it the model developed in the thesis:
the heterogeneity in choices considered by the model will indeed be entirely explainable with differences across individuals,
while in the simulated data there will be another source of randomness determined by the parameter \(\mu\).

A theoretical analysis could be performed,
to prove that a logit model would yield the same distribution of departure times as the deterministic case with some changes on the distributions of the parameters \(\alpha, \beta, \gamma, t^*\).
This analysis is anyway considered out of the scope of this thesis and will not be performed:
to achieve convergence,
a value of \(\mu\) as low as possible will be chosen to keep the simulator converging,
while having a dataset close enough to the deterministic case.

On top of this problem, evaluating the model with simulated data presents some technical challenges.
The next section describe them, and the methods for addressing them.

\subsection{Challenges in the Evaluation with Synthetic Data}
\label{sec:sim_tech}

Evaluating the model on simulated data is not straightforward,
and for finalizing an evaluation several difficulties have to be overcome.
In this Section, all the necessary steps for performing a successful evaluation,
and the corresponding difficulties, will be described.

The first step needed to perform the model evaluation is to retrieve the data.
The first main challenge for this task regards running the simulator:
METROPOLIS2 is indeed not a commercial software,
its documentation is not complete and the user experience is not close to what a normal software offers.
Thanks to the kind support of Lucas Javaudin,
the main author of the simulator, this difficulty was efficiently overcome.

Once the software is ready to be used,
the population on which the simulation is run has to be determined.
This is not a trivial task:
equilibrium is indeed defined as the situation in which none of the agents have any interest in behaving differently from how they are doing;
given the travel time function at equilibrium,
agents will be (in average) indifferent on the choice of departure time they do,
yielding a situation that is not interesting for the developed model,
which is based on what the agents prefer to do.
In other words, the model must be run out of equilibrium, that is when the travel time function is exogenous rather than endogenous.

This could simply be achieved by only running the demand model on a given travel time function.
This approach would anyway have two major drawbacks:
on the one hand, it would require modifying the source code of the simulator,
which is not open source;
on the other hand, it would yield an evaluation procedure extremely similar to the one described in Section \ref{sec:eval_synth}:
each agent would indeed independently minimize a cost function
(or a slightly modified version of it, if taking into account the logit model).
This would make this method less powerful and generalizable,
since it will restrict the evaluation to a purely theoretical setting.

Instead of this another, more realistic approach will be taken:
the studied commuters will be a minority of the totality,
so that their choices will have a negligible effect on their experienced travel time
(as happens in reality, where the decision of each commuter has a negligible effect on the travel time function).
In the simplest case, the simulator will model the behaviour of two groups of users:
the first one, representing the majority of the commuters,
will have their parameters distributed according to some distribution,
of interest only for the impact it has on the travel time function.
The second group, representing a small minority of the commuters,
will have the parameters distributed according to a distribution of the chosen form (as in Section \ref{sec:run_synth_dataset}),
parametrized by some parameter \(\theta\).
The effective departure times of the users in the second group are used,
and the maximum likelihood estimator will find the parameter \(\theta\) determining the distributions of the parameters of the group.
The travel time function, on the other hand,
will mainly depend on the choices of the large group.
A 2-dimensional projection of the parameter \(\theta\) is shown in figure~\ref{fig:par_groups_sim}.

\begin{figure}
  \centering
  \includegraphics[width=.8\textwidth]{distr_metr}
  \caption{Projection of the parameter \(\theta\) on a plane parametrized by the parameters representing the means of \(\beta\) and \(\gamma\).
    As can be seen, the population is clearly divided into two groups:
    a big group, that is mainly meant to shape the travel time (group 1)
  and a smaller group, whose departure times will be studied.}
  \label{fig:par_groups_sim}
\end{figure}

Once the population has been built and the simulator configured,
running the simulation yields some data points about the experienced travel time at equilibrium,
at each one of the simulated time points.
The points are clearly, as expected in a realistic environment, noisy.
Figure~\ref{fig:tdata} shows a typical travel time pattern generated by the simulator.

\begin{figure}
  \centering
  \includegraphics[width=.7\textwidth]{tdata_no_f}
  \caption{Observed arrival times for data simulated with the METROPOLIS2 software.
    Despite the consistency of the data (ascribable to the good convergency of the model to the theoretical solution),
  some noise is still present, and interpolating them with a smooth function may not be trivial.}
  \label{fig:tdata}
\end{figure}

Given how the pattern is behaved, interpolating it with a smooth function whose derivative can be approximated at any point is not trivial.
Two main approaches were considered:
one is to locally interpolate it with gluable functions,
such as polynomials constrained on the points on which they are glued,
yielding a method called, in the literature \textit{SPline interpolation} \parencite{19671}.
A second approach is to define a parametric function, with a little number of parameters,
and run an optimization algorithm on top of it.
Please note that the methods are not completely different:
SPlines are indeed parametric functions, and fitting them is an optimization problem.
An hybrid approach is adopted:
a piecewise function, pieces of which can be polynomial (that is, SPlines),
is defined and an optimization algorithm is run on the parameters of it.
This allows to set some constraint on the desired theoretical properties of the function by suitably defining the function,
while being able to have enough degrees of freedom,
as long as a wise choice is made regarding the interpolating function.

After running the model on the retrieved data, more complex scenarios can be considered.
A more complex population, composed of more than two groups, can be taken into account:
as in the simpler case, the model will estimate parameters for a small group of users,
whose action on the experienced travel time is negligible.
Alternatively, simulations can be performed for more complex road networks:
several bottlenecks, arranged in different ways, can be simulated.

By improving the simulation in these two ways,
the simulated data can be made to progressively converge to real data,
which is the final goal of the project.

\section{Evaluation on Real Data}
\label{sec:eval_real}

Evaluating the model on real data poses several challenges,
which cannot be easily overcome.
In this Section, the main ones are listed, and the problems in solving them are described.

The first problem arises in retrieving the data:
as briefly written in Section~\ref{sec:data-about-travel},
data about travel time are not difficult to retrieve.
At the same time, data about experienced departure time of a population can be retrieved in different ways:
surveys can be made (for instance, EPFL mobility survey is a nice data source, including what was the last departure time from home for each user),
or some sensors can be used to retrieve Revealed Preferences, rather than Stated Preferences,
for a population (e. g., by using a mobile phone application).
Survey data have anyway the drawbacks that were explained in Section~\ref{sec:estim-param-alpha},
and other ways of finding these kinds of data are out of the scope of this thesis
(but may be the topic of future works).

Data sets exclusively regarding travel times are anyway difficult to use for this use case:
coherent data for departure times and travel times are indeed needed,
to deploy the developed model.
Using the data sources presented above,
the only way to obtain these data is by using survey data for obtaining the departure times and using some private service,
such as Google Maps API,
for retrieving data about travel times for the exact routes driven by who answered the survey.
This method has, as explained above, some drawbacks.
It could be anyway used, as the data are sufficient to deploy the model.

Apart from this, the evaluation on real data reveals another, deeper problem:
as explained in chapter \ref{cha:introduction},
studies involving Vickrey model and real data are extremely lacking.
A recent paper \parencite{https://doi.org/10.1111/iere.12692} notes a deep problem in doing these kinds of study:
slopes computed using real data are indeed much lower than what one would expect from theoretical studies on Vickrey's model at equilibrium.

The model developed in this thesis is anyway not studying equilibrium dynamics,
and is thus not directly affected by the highlighted problem.
It is anyway affected by it in two different ways, in the theoretical and practical levels.
On the theoretical level, the method could lose relevance:
it is indeed based on a theory that is currently showing a relevant flaw,
and the models developed by it could thus be flawed themselves in case the theory is shown not to work.
On the practical level, on the other hand,
having high slopes in the travel time function is essential for the model to work:
with low enough slopes,
the predicted values for the parameters of the studied population would be consistently different from the ones predicted by the theory, and shown in Section \ref{sec:estim-param-alpha}.

To solve this issue, different approaches are being developed:
\textcite{https://doi.org/10.1111/iere.12692} suggests a particular distribution of the population,
in which some travellers (which are called, in the article, \textit{inframarginal}) have extremely high values of \(\beta/\alpha, \gamma/\alpha\).
This solution is compatible with the model developed here:
it indeed makes it possible to have a group of people with low values for the said parameters,
and the existence of the group would be justified by the existence of the inframarginal travellers,
who make the values reported in the existent theory possible.
This solution is anyway not, as far as I am concerned,
a systematic solution to the weakness shown by the model.
A group of researchers from EPFL and Cergy University (with whom I am currently working) are currently working on an alternative solution of the problem,
by taking into account the uncertainty on the travel time expected by the user.
The model shows preliminary good results, and will be developed in the near future.
It is anyway out of the scope of the thesis.

These remarks on the difficulties of validating the model on real data close the chapter about methodology.
The next chapter will describe the construction of the model,
and show how the model performs on the evaluation frameworks,
where the evaluation can be done.


%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../main"
%%% End:
